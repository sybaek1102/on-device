#!/usr/bin/env python3
"""
create_residual_model_train_data_hnsw.py
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
build_index_hnsw.py Í≤∞Í≥ºÎ¨ºÏùÑ Ïù¥Ïö©Ìï¥ Residual Feature / LabelÏùÑ ÏÉùÏÑ±Ìï©ÎãàÎã§.
create_residual_model_train_data.py Ïùò HNSW Î≤ÑÏ†Ñ.

[IndexHNSWPQ Íµ¨Ï°∞ Ï∞®Ïù¥]
  - pq_index.reconstruct_n() ÎØ∏ÏßÄÏõê ‚Üí storage.pq.decode(codes) Î°ú Î≥µÏõê
  - PQ object Ï†ëÍ∑º: faiss.downcast_index(hnsw_index.storage).pq
  - PQ codes Ï†ëÍ∑º: faiss.vector_to_array(storage.codes)

[Ï∂úÎ†•]
  residual_features_hnsw.npz  : shape (160000, 16, 9)
  residual_label_hnsw.npz     : shape (160000, 1)

[Ï†ÄÏû• ÏúÑÏπò]
  data/model/residual_hnsw/

[ÏùòÏ°¥ ÌååÏùº]
  - {CREATION_DATE}_hnswpq.index         : Base HNSW PQ Index (faiss)
  - {CREATION_DATE}_residual_pq_hnsw.index : Residual PQ Index (faiss)
  - bigann_base.bvecs                    : Base vectors
  - bigann_query.bvecs                   : Query vectors
"""

import faiss
faiss.omp_set_num_threads(8)

import numpy as np
import os
import time
from tqdm import tqdm

# =============================================================================
# üîπ Configuration
# =============================================================================
CREATION_DATE = "2026022007"

DATA_DIR   = "/home/syback/vectorDB/ann_datasets/sift1B"
BASE_FILE  = os.path.join(DATA_DIR, "bigann_base.bvecs")
QUERY_FILE = os.path.join(DATA_DIR, "bigann_query.bvecs")

INDEX_DIR       = "/home/syback/vectorDB/on-device/data/index"
HNSW_INDEX_PATH = os.path.join(INDEX_DIR, f"{CREATION_DATE}_hnswpq.index")
RES_INDEX_PATH  = os.path.join(INDEX_DIR, f"{CREATION_DATE}_residual_pq_hnsw.index")

FEATURE_SAVE_DIR  = "/home/syback/vectorDB/on-device/data/model/residual_hnsw"
FEATURE_SAVE_PATH = os.path.join(FEATURE_SAVE_DIR, "residual_features_hnsw.npz")
LABEL_SAVE_PATH   = os.path.join(FEATURE_SAVE_DIR, "residual_label_hnsw.npz")

NUM_BASE      = 10_000_000
NUM_QUERY     = 10_000
CANDIDATES    = 16
DIM           = 128
NUM_SUBSPACES = 16
SUB_DIM       = DIM // NUM_SUBSPACES   # 8

# HNSW Search ÌíàÏßà (ÌïôÏäµ Îç∞Ïù¥ÌÑ∞ ÏÉùÏÑ±Ïö©: ÎÜíÍ≤å ÏÑ§Ï†ï)
HNSW_EF_SEARCH = 256

# =============================================================================
# üîπ Helper functions
# =============================================================================
def load_bvecs(fname, num_vectors=None):
    with open(fname, "rb") as f:
        d = np.frombuffer(f.read(4), dtype="int32")[0]
    filesize    = os.path.getsize(fname)
    record_size = 4 + d
    total       = filesize // record_size
    n = min(num_vectors, total) if num_vectors else total
    mm = np.memmap(fname, dtype="uint8", mode="r")[:n * record_size]
    return mm.reshape(n, record_size)[:, 4:].astype("float32")

def decode_pq(pq_obj, codes):
    """
    pq_obj.decode(codes) ‚Üí (n, d) float32
    codes: (n, M) uint8
    """
    return pq_obj.decode(codes).reshape(len(codes), pq_obj.d)

# =============================================================================
# üîπ Main
# =============================================================================
if __name__ == "__main__":
    t0 = time.perf_counter()

    # -------------------------------------------------------------------------
    # Step 1. ÌååÏùº ÌôïÏù∏
    # -------------------------------------------------------------------------
    print("=" * 70)
    print("  Residual Feature Generation  [HNSW version]")
    print("=" * 70)
    print(f"\n[Config]")
    print(f"  CREATION_DATE   : {CREATION_DATE}")
    print(f"  HNSW Index      : {HNSW_INDEX_PATH}")
    print(f"  Residual Index  : {RES_INDEX_PATH}")
    print(f"  Base File       : {BASE_FILE}")
    print(f"  Query File      : {QUERY_FILE}")
    print(f"  efSearch        : {HNSW_EF_SEARCH}  (ÌïôÏäµ Îç∞Ïù¥ÌÑ∞Ïö© Í≥†ÌíàÏßà ÌÉêÏÉâ)")

    for path in [HNSW_INDEX_PATH, RES_INDEX_PATH, BASE_FILE, QUERY_FILE]:
        if not os.path.exists(path):
            raise FileNotFoundError(f"ÌååÏùºÏùÑ Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§: {path}")
    print("\n  ‚úì Î™®Îì† ÏûÖÎ†• ÌååÏùº ÌôïÏù∏ ÏôÑÎ£å\n")

    # -------------------------------------------------------------------------
    # Step 2. Îç∞Ïù¥ÌÑ∞ Î°úÎìú
    # -------------------------------------------------------------------------
    print(">>> [1/5] Îç∞Ïù¥ÌÑ∞ Î°úÎî© Ï§ë...")
    xb = load_bvecs(BASE_FILE, NUM_BASE)    # (10M, 128)
    xq = load_bvecs(QUERY_FILE, NUM_QUERY)  # (10000, 128)
    print(f"    - Base  vectors : {xb.shape}")
    print(f"    - Query vectors : {xq.shape}")

    # -------------------------------------------------------------------------
    # Step 3. Faiss Index Î°úÎìú Î∞è PQ Ï†ïÎ≥¥ Ï∂îÏ∂ú
    # -------------------------------------------------------------------------
    print("\n>>> [2/5] Faiss Index Î°úÎî© Î∞è PQ Centroid Ï∂îÏ∂ú Ï§ë...")

    hnsw_index = faiss.read_index(HNSW_INDEX_PATH)
    res_index  = faiss.read_index(RES_INDEX_PATH)
    hnsw_index.hnsw.efSearch = HNSW_EF_SEARCH
    print(f"    - HNSW Index ntotal    : {hnsw_index.ntotal:,}")
    print(f"    - Residual Index ntotal: {res_index.ntotal:,}")

    # ‚îÄ‚îÄ PQ object Ï†ëÍ∑º (IndexHNSWPQ Íµ¨Ï°∞ Ï∞®Ïù¥) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # IndexHNSWPQ: storage = IndexPQ ‚Üí faiss.downcast_index(storage) ÌïÑÏöî
    hnsw_storage = faiss.downcast_index(hnsw_index.storage)   # IndexPQ
    pq_obj       = hnsw_storage.pq                             # ProductQuantizer

    res_index_down = faiss.downcast_index(res_index)
    res_pq_obj     = res_index_down.pq

    M_pq = pq_obj.M; K_pq = pq_obj.ksub; dsub = pq_obj.dsub

    pq_centroids  = faiss.vector_to_array(pq_obj.centroids).reshape(M_pq, K_pq, dsub)
    res_centroids = faiss.vector_to_array(res_pq_obj.centroids).reshape(M_pq, K_pq, dsub)
    print(f"    - PQ  Centroids shape  : {pq_centroids.shape}")
    print(f"    - Res Centroids shape  : {res_centroids.shape}")

    # ‚îÄ‚îÄ HNSW ÎÇ¥Ïû• PQ codes Ï†ÑÏ≤¥ Ï∂îÏ∂ú ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # IndexHNSWPQ: ÏΩîÎìúÎäî storage.codes Ïóê Ï†ÄÏû•
    pq_codes_all = faiss.vector_to_array(hnsw_storage.codes).reshape(
        hnsw_index.ntotal, M_pq).copy()   # (10M, 16) uint8
    print(f"    - HNSW PQ codes shape  : {pq_codes_all.shape}  (from storage)")

    # -------------------------------------------------------------------------
    # Step 4. Base Î≤°ÌÑ∞Ïùò PQ Î≥µÏõê Î∞è Residual PQ code Í≥ÑÏÇ∞
    # -------------------------------------------------------------------------
    print("\n>>> [3/5] Base Î≤°ÌÑ∞ PQ Î≥µÏõê Î∞è Residual code Í≥ÑÏÇ∞ Ï§ë...")

    # IndexHNSWPQÎäî reconstruct_n() ÎØ∏ÏßÄÏõê ‚Üí storage.pq.decode() Î°ú ÏßÅÏ†ë Î≥µÏõê
    # Residual codeÎäî ÏõêÎ≥∏Í≥º ÎèôÏùºÌïòÍ≤å res_pq_obj.compute_codes() ÏÇ¨Ïö©
    res_codes_base = np.zeros((NUM_BASE, M_pq), dtype=np.uint8)

    BATCH = 500_000
    for start in tqdm(range(0, NUM_BASE, BATCH), desc="  Encoding Residual"):
        end   = min(start + BATCH, NUM_BASE)
        chunk = xb[start:end]

        # PQ Î≥µÏõê: storage.pq.decode(codes_chunk)
        codes_chunk = pq_codes_all[start:end]       # (n, M) uint8
        pq_recon    = decode_pq(pq_obj, codes_chunk) # (n, 128)
        residuals   = chunk - pq_recon

        # Residual PQ code
        res_codes_base[start:end] = res_pq_obj.compute_codes(residuals)

    print(f"    - pq_codes_all   : {pq_codes_all.shape}  dtype={pq_codes_all.dtype}")
    print(f"    - res_codes_base : {res_codes_base.shape}  dtype={res_codes_base.dtype}")

    # -------------------------------------------------------------------------
    # Step 5. Query Search ‚Äî top-16 ÌõÑÎ≥¥ Ï∂îÏ∂ú (HNSW search)
    # -------------------------------------------------------------------------
    print(f"\n>>> [4/5] Query Search (top-{CANDIDATES}, efSearch={HNSW_EF_SEARCH}) ÏàòÌñâ Ï§ë...")

    _, I = hnsw_index.search(xq, CANDIDATES)   # I: (10000, 16)
    print(f"    - Search result I : {I.shape}")

    # -------------------------------------------------------------------------
    # Step 6. Feature ÏÉùÏÑ±  ‚Üí (160000, 16, 9) / Label ‚Üí (160000, 1)
    # -------------------------------------------------------------------------
    print("\n>>> [5/5] Feature Engineering ÏàòÌñâ Ï§ë...")

    N_total  = NUM_QUERY * CANDIDATES   # 160000
    flat_idx = I.flatten()              # (160000,)

    Q_exp  = np.repeat(xq, CANDIDATES, axis=0)   # (160000, 128)
    X_cand = xb[flat_idx]                         # (160000, 128)
    pq_c   = pq_codes_all[flat_idx]               # (160000, 16) ‚Üê HNSW storageÏóêÏÑú
    res_c  = res_codes_base[flat_idx]             # (160000, 16)

    features_list = []
    labels_acc    = np.zeros((N_total, 1), dtype=np.float32)

    for m in tqdm(range(NUM_SUBSPACES), desc="  Subspace Feature"):
        s = m * SUB_DIM; e = (m + 1) * SUB_DIM

        Q_sub    = Q_exp[:, s:e]               # (160000, 8)
        P_sub    = pq_centroids[m][pq_c[:, m]] # (160000, 8)
        diff_vec = Q_sub - P_sub               # Q - P

        res_reconstructed = res_centroids[m][res_c[:, m]]  # (160000, 8)

        # Feature
        product_vec            = diff_vec * res_reconstructed              # (160000, 8)
        feat_res_norm          = np.sqrt(np.sum(res_reconstructed ** 2, axis=1, keepdims=True)) / np.sqrt(SUB_DIM)
        feat_m                 = np.concatenate([product_vec, feat_res_norm], axis=1)  # (160000, 9)
        features_list.append(feat_m)

        # Label: dot(Q-P, X-P)
        X_sub     = X_cand[:, s:e]
        true_res  = X_sub - P_sub
        dot_qp_xp = np.sum(diff_vec * true_res, axis=1, keepdims=True)
        labels_acc += dot_qp_xp

    X_final = np.stack(features_list, axis=1)   # (160000, 16, 9)
    y_final = labels_acc                         # (160000, 1)
    print(f"\n    - Final Feature Shape : {X_final.shape}  (Expected: ({N_total}, 16, 9))")
    print(f"    - Final Label   Shape : {y_final.shape}  (Expected: ({N_total}, 1))")

    # -------------------------------------------------------------------------
    # Step 7. Ï†ÄÏû•
    # -------------------------------------------------------------------------
    os.makedirs(FEATURE_SAVE_DIR, exist_ok=True)
    np.savez_compressed(FEATURE_SAVE_PATH, data=X_final)
    print(f"\n    ‚úì Saved Feature: {FEATURE_SAVE_PATH}")
    np.savez_compressed(LABEL_SAVE_PATH, data=y_final)
    print(f"    ‚úì Saved Label  : {LABEL_SAVE_PATH}")

    elapsed = time.perf_counter() - t0
    print(f"\n  Total elapsed: {elapsed:.1f}s")
    print("=" * 70)
