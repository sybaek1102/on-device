#!/usr/bin/env python3
"""
create_reranking_model_train_data_hnsw.py
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
build_index_hnsw.py ê²°ê³¼ë¬¼ + residual_hnsw OOF ì˜ˆì¸¡ìœ¼ë¡œ
Re-ranking Feature/Labelì„ ìƒì„±í•©ë‹ˆë‹¤. (HNSW ë²„ì „)

[IndexHNSWPQ êµ¬ì¡° ì°¨ì´]
  - PQ object ì ‘ê·¼: faiss.downcast_index(hnsw_index.storage).pq
  - PQ codes: faiss.vector_to_array(storage.codes) ë¡œ ì „ì²´ ì¶”ì¶œ
  - PQ ë³µì›: pq_obj.decode(codes) ì‚¬ìš© (reconstruct_n ë¯¸ì§€ì›)

[ì¶œë ¥]
  re-ranking_features_hnsw.npz : shape (10000, 33)  â†’  data/model/re-ranking_hnsw/

[Label ì •ì˜]
  0: pred_top1 == gt_top1          (ì´ë¯¸ 1ë“±ì´ ì •ë‹µ)
  1: ê·¸ ì™¸                          (re-ranking í•„ìš” or ì •ë‹µ ì—†ìŒ)
"""

import faiss
faiss.omp_set_num_threads(8)

import numpy as np
import os
import time
from tqdm import tqdm

# =============================================================================
# ğŸ”¹ Configuration â€” ì—¬ê¸°ì„œ ì§ì ‘ ì„¤ì •í•˜ì„¸ìš”
# =============================================================================

# build_index.py ì‹¤í–‰ ì‹œ ì°íŒ creation_date ê°’
CREATION_DATE = "2026022007"

# Base / Query bvecs
DATA_DIR   = "/home/syback/vectorDB/ann_datasets/sift1B"
BASE_FILE  = os.path.join(DATA_DIR, "bigann_base.bvecs")
QUERY_FILE = os.path.join(DATA_DIR, "bigann_query.bvecs")

# Ground Truth ivecs
GT_FILE = os.path.join(DATA_DIR, "gnd", "idx_10M.ivecs")

# Faiss Index (HNSWPQ)
INDEX_DIR        = "/home/syback/vectorDB/on-device/data/index"
HNSW_INDEX_PATH  = os.path.join(INDEX_DIR, f"{CREATION_DATE}_hnswpq.index")

HNSW_EF_SEARCH   = 256   # í•™ìŠµ ë°ì´í„° ìƒì„±ìš© ê³ í’ˆì§ˆ íƒìƒ‰

# Residual OOF ì˜ˆì¸¡ (model_train_residual_hnsw.py ê²°ê³¼)
OOF_PRED_PATH = "/home/syback/vectorDB/on-device/data/model/residual_hnsw/oof_pred.npz"

# ì¶œë ¥ ê²½ë¡œ
OUTPUT_DIR  = "/home/syback/vectorDB/on-device/data/model/re-ranking_hnsw"
OUTPUT_PATH = os.path.join(OUTPUT_DIR, "re-ranking_features_hnsw.npz")

# íŒŒë¼ë¯¸í„°
NUM_BASE      = 10_000_000
NUM_QUERY     = 10_000
CANDIDATES    = 16
DIM           = 128
NUM_SUBSPACES = 16
SUB_DIM       = DIM // NUM_SUBSPACES   # 8

# =============================================================================
# ğŸ”¹ Helper: bvecs ë¡œë”
# =============================================================================
def load_bvecs(fname, num_vectors=None):
    with open(fname, "rb") as f:
        d = np.frombuffer(f.read(4), dtype="int32")[0]
    filesize    = os.path.getsize(fname)
    record_size = 4 + d
    total       = filesize // record_size
    if num_vectors is not None:
        num_vectors = min(num_vectors, total)
    else:
        num_vectors = total
    mm   = np.memmap(fname, dtype="uint8", mode="r")
    mm   = mm[: num_vectors * record_size]
    data = mm.reshape(num_vectors, record_size)[:, 4:]
    return data.astype("float32")

def load_ivecs(fname):
    """ivecs íŒŒì¼ ë¡œë“œ â†’ (N, k) int32"""
    mm          = np.memmap(fname, dtype="int32", mode="r")
    k           = mm[0]
    record_size = k + 1
    nvecs       = mm.shape[0] // record_size
    return mm.reshape(nvecs, record_size)[:, 1:].copy()

# =============================================================================
# ğŸ”¹ Main
# =============================================================================
if __name__ == "__main__":
    t0 = time.perf_counter()

    print("=" * 70)
    print("  Re-ranking Feature & Label Generation")
    print("=" * 70)
    print(f"\n[Config]")
    print(f"  CREATION_DATE   : {CREATION_DATE}")
    print(f"  HNSW Index      : {HNSW_INDEX_PATH}")
    print(f"  OOF Pred        : {OOF_PRED_PATH}")
    print(f"  GT File         : {GT_FILE}")

    for path in [HNSW_INDEX_PATH, OOF_PRED_PATH, BASE_FILE, QUERY_FILE, GT_FILE]:
        if not os.path.exists(path):
            raise FileNotFoundError(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {path}")
    print("\n  âœ“ ëª¨ë“  ì…ë ¥ íŒŒì¼ í™•ì¸ ì™„ë£Œ\n")

    # -------------------------------------------------------------------------
    # Step 1. ë°ì´í„° ë¡œë“œ
    # -------------------------------------------------------------------------
    print(">>> [1/6] ë°ì´í„° ë¡œë”© ì¤‘...")
    xb = load_bvecs(BASE_FILE, NUM_BASE)    # (10M, 128)
    xq = load_bvecs(QUERY_FILE, NUM_QUERY)  # (10000, 128)
    print(f"    - Base  vectors : {xb.shape}")
    print(f"    - Query vectors : {xq.shape}")

    # -------------------------------------------------------------------------
    # Step 2. GT ë¡œë“œ
    # -------------------------------------------------------------------------
    print("\n>>> [2/6] Ground Truth ë¡œë“œ ì¤‘...")
    gt_idx = load_ivecs(GT_FILE)            # (10000, k_gt)
    gt_top1 = gt_idx[:, 0]                 # (10000,)  GT 1ë“± index
    print(f"    - GT shape      : {gt_idx.shape}")

    # -------------------------------------------------------------------------
    # Step 3. PQ Index ë¡œë“œ + Query Search
    # -------------------------------------------------------------------------
    print("\n>>> [3/6] HNSW Index ë¡œë“œ & Query Search ì¤‘...")
    hnsw_index = faiss.read_index(HNSW_INDEX_PATH)
    hnsw_index.hnsw.efSearch = HNSW_EF_SEARCH

    # â”€â”€ IndexHNSWPQ: storage ë¥¼ downcast í›„ pq object ì ‘ê·¼ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    hnsw_storage = faiss.downcast_index(hnsw_index.storage)   # IndexPQ
    pq_obj       = hnsw_storage.pq                             # ProductQuantizer
    M_pq         = pq_obj.M       # 16
    K_pq         = pq_obj.ksub    # 256
    dsub         = pq_obj.dsub    # 8

    pq_centroids = faiss.vector_to_array(pq_obj.centroids).reshape(M_pq, K_pq, dsub)

    # HNSW storage ì—ì„œ PQ codes ì „ì²´ ì¶”ì¶œ (10M, 16)
    pq_codes_all = faiss.vector_to_array(hnsw_storage.codes).reshape(
        hnsw_index.ntotal, M_pq).copy()   # uint8

    # Query Search (HNSW)
    D_pq, I = hnsw_index.search(xq, CANDIDATES)
    print(f"    - HNSW Index ntotal : {hnsw_index.ntotal:,}")
    print(f"    - efSearch          : {HNSW_EF_SEARCH}")
    print(f"    - Search I shape    : {I.shape}")
    print(f"    - Search D shape    : {D_pq.shape}")

    # -------------------------------------------------------------------------
    # Step 4. OOF Residual ì˜ˆì¸¡ ë¡œë“œ
    # -------------------------------------------------------------------------
    print("\n>>> [4/6] OOF Residual ì˜ˆì¸¡ ë¡œë“œ ì¤‘...")
    with np.load(OOF_PRED_PATH) as f:
        oof_preds = f["pred"]               # (160000, 1)
    oof_preds_2d = oof_preds.reshape(NUM_QUERY, CANDIDATES)  # (10000, 16)
    print(f"    - OOF pred shape  : {oof_preds.shape} â†’ reshaped: {oof_preds_2d.shape}")

    # -------------------------------------------------------------------------
    # Step 5. Feature ê³„ì‚°
    # -------------------------------------------------------------------------
    print("\n>>> [5/6] Feature ê³„ì‚° ì¤‘...")

    flat_idx = I.flatten()              # (160000,)

    # --- [Feature A] PQ Distance per subspace ---
    # HNSW storage codesì—ì„œ í›„ë³´ë²¡í„°ì˜ PQ code ì¶”ì¶œ
    pq_codes_cand = pq_codes_all[flat_idx]   # (160000, 16) uint8

    # Query expand
    Q_exp = np.repeat(xq, CANDIDATES, axis=0)           # (160000, 128)

    pq_dist_flat = np.zeros((NUM_QUERY * CANDIDATES, NUM_SUBSPACES), dtype=np.float32)
    for m in tqdm(range(NUM_SUBSPACES), desc="  PQ dist subspace"):
        start_col = m * SUB_DIM
        end_col   = (m + 1) * SUB_DIM
        Q_sub     = Q_exp[:, start_col:end_col]              # (160000, 8)
        P_sub     = pq_centroids[m][pq_codes_cand[:, m]]    # (160000, 8)
        diff      = Q_sub - P_sub
        pq_dist_flat[:, m] = np.sum(diff ** 2, axis=1)      # ||Q-P||Â² per subspace

    pq_dist_2d = pq_dist_flat.reshape(NUM_QUERY, CANDIDATES, NUM_SUBSPACES)  # (10000, 16, 16)
    # í›„ë³´ë³„ subspace í•©ì‚° â†’ (10000, 16)  (ê° í›„ë³´ì˜ ì „ì²´ PQ ê±°ë¦¬)
    pq_dist_per_cand = pq_dist_2d.sum(axis=2)              # (10000, 16)

    print(f"    - PQ Distance shape : {pq_dist_per_cand.shape}")

    # --- [Feature B] ||X-P||Â² ì§ì ‘ ê³„ì‚° ---
    X_cand = xb[flat_idx].reshape(NUM_QUERY, CANDIDATES, DIM)  # (10000, 16, 128)

    # PQ ì¬êµ¬ì„± ë²¡í„° ê³„ì‚°
    X_flat       = xb[flat_idx]                          # (160000, 128)
    pq_recon_flat = np.zeros_like(X_flat)
    ENCODE_BATCH  = 500_000

    for start in tqdm(range(0, len(flat_idx), ENCODE_BATCH), desc="  Recon XP (HNSW decode)"):
        end = min(start + ENCODE_BATCH, len(flat_idx))
        codes_chunk = pq_codes_all[flat_idx[start:end]]  # (n, 16) uint8 - HNSW storage ì—ì„œ
        # pq_obj.decode: HNSW ì „ìš© ë³µì› ë°©ì‹
        recon_chunk = pq_obj.decode(codes_chunk).reshape(end - start, DIM)
        pq_recon_flat[start:end] = recon_chunk

    residual_xp = X_flat - pq_recon_flat                          # (160000, 128)  X - P
    xp_normsq   = np.sum(residual_xp ** 2, axis=1)               # (160000,)  ||X-P||Â²
    xp_normsq_2d = xp_normsq.reshape(NUM_QUERY, CANDIDATES)      # (10000, 16)

    print(f"    - ||X-P||Â² shape    : {xp_normsq_2d.shape}")

    # --- [Feature B final] ||X-P||Â² - 2 * OOF_pred ---
    residual_feat = xp_normsq_2d - 2.0 * oof_preds_2d            # (10000, 16)
    print(f"    - Residual feat     : {residual_feat.shape}")

    # --- Feature ë³‘í•© (10000, 32) ---
    final_features = np.hstack([pq_dist_per_cand, residual_feat])  # (10000, 32)
    print(f"    - Final features    : {final_features.shape}")

    # -------------------------------------------------------------------------
    # Step 6. Label ìƒì„± (01_create_re-ranking_label.py ë™ì¼ ë¡œì§)
    # -------------------------------------------------------------------------
    print("\n>>> [6/6] Label ìƒì„± ì¤‘...")

    labels = np.zeros((NUM_QUERY, 1), dtype=np.int32)
    for i in range(NUM_QUERY):
        pred_top1   = I[i, 0]
        pred_all    = I[i, :]
        gt          = gt_top1[i]

        if pred_top1 == gt:
            labels[i, 0] = 0   # ì´ë¯¸ 1ë“±ì´ ì •ë‹µ
        else:
            labels[i, 0] = 1   # re-ranking í•„ìš” or ì •ë‹µ ì—†ìŒ

    unique, counts = np.unique(labels, return_counts=True)
    for u, c in zip(unique, counts):
        print(f"    - Label {u}: {c:,} ({c/NUM_QUERY*100:.2f}%)")

    # -------------------------------------------------------------------------
    # ì €ì¥
    # -------------------------------------------------------------------------
    final_data = np.hstack([final_features, labels.astype(np.float32)])  # (10000, 33)
    print(f"\n    - Final data shape  : {final_data.shape}")

    os.makedirs(OUTPUT_DIR, exist_ok=True)
    np.savez_compressed(OUTPUT_PATH, data=final_data)
    print(f"\n    âœ“ Saved: {OUTPUT_PATH}")

    elapsed = time.perf_counter() - t0
    print(f"\n  Total elapsed: {elapsed:.1f}s")

    print("\n" + "=" * 70)
    print("[Feature êµ¬ì„± (10000, 33)]")
    print("  Index  0~15 : PQ Distance    (||Q-P||\u00b2  per each of 16 candidates)")
    print("  Index 16~31 : Residual Dist  (||X-P||\u00b2 - 2\u00b7pred(dot(Q-P,X-P)))")
    print("  Index 32    : Label          (0: \uc815\ub2f5\uc774 \uc774\ubbf8 1\ub4f1 / 1: re-ranking \ud544\uc694)")
    print("=" * 70)
